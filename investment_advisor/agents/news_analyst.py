"""
News Analysis Agent

Analyzes news, social media sentiment, and market events.
"""

from typing import Any, Dict, List
import logging
from datetime import datetime, timedelta
import re

from langchain.prompts import PromptTemplate
from pydantic import Field

from .base import InvestmentAgent
from ..core.exceptions import AnalysisError

logger = logging.getLogger(__name__)


class NewsAnalysisAgent(InvestmentAgent):
    """Agent specialized in news and media sentiment analysis."""
    
    name: str = "ë‰´ìŠ¤ë¶„ì„ê°€"
    description: str = "ë‰´ìŠ¤, ì†Œì…œ ë¯¸ë””ì–´, ì‹œì¥ ì´ë²¤íŠ¸ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€"
    
    # Prompt template for news analysis
    prompt: PromptTemplate = PromptTemplate(
        input_variables=["ticker", "market", "company_name", "news_data"],
        template="""ë‹¹ì‹ ì€ ê¸ˆìœµ ë‰´ìŠ¤ì™€ ë¯¸ë””ì–´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì¢…ëª©: {ticker}
íšŒì‚¬ëª…: {company_name}
ì‹œì¥: {market}

ë‰´ìŠ¤ ë° ë¯¸ë””ì–´ ë°ì´í„°:
{news_data}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì£¼ìš” ë‰´ìŠ¤ ë¶„ì„**
   - ìµœê·¼ ì¤‘ìš” ë‰´ìŠ¤ ë° ê³µì‹œ ì‚¬í•­
   - ë‰´ìŠ¤ì˜ ê¸ì •/ë¶€ì • ì˜í–¥ë„ í‰ê°€
   - ì‹œì¥ ë°˜ì‘ ì˜ˆìƒ

2. **ê°ì„± ë¶„ì„**
   - ì „ë°˜ì ì¸ ë¯¸ë””ì–´ í†¤ (ê¸ì •/ì¤‘ë¦½/ë¶€ì •)
   - ê°ì„± ë³€í™” ì¶”ì´
   - ì£¼ìš” í‚¤ì›Œë“œ ë° í…Œë§ˆ

3. **ì´ë²¤íŠ¸ ì˜í–¥ í‰ê°€**
   - ì˜ˆì •ëœ ì£¼ìš” ì´ë²¤íŠ¸ (ì‹¤ì  ë°œí‘œ, ì œí’ˆ ì¶œì‹œ ë“±)
   - ì´ë²¤íŠ¸ì˜ ì ì¬ì  ì˜í–¥
   - ì‹œì¥ ê¸°ëŒ€ì¹˜ vs ì‹¤ì œ ê°€ëŠ¥ì„±

4. **ì†Œì…œ ë¯¸ë””ì–´ ë° ì—¬ë¡ **
   - ì†Œì…œ ë¯¸ë””ì–´ ì–¸ê¸‰ëŸ‰ ì¶”ì´
   - íˆ¬ìì ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘
   - ë£¨ë¨¸ ë° ì¶”ì¸¡ì„± ì •ë³´ í‰ê°€

5. **ë‰´ìŠ¤ ê¸°ë°˜ íˆ¬ì ì‹œê·¸ë„**
   - ë‰´ìŠ¤ ëª¨ë©˜í…€ (ì¦ê°€/ê°ì†Œ)
   - ì •ë³´ì˜ ì‹ ë¢°ì„± í‰ê°€
   - ë‹¨ê¸°/ì¤‘ê¸° ì˜í–¥ ì „ë§

êµ¬ì²´ì ì¸ ë‰´ìŠ¤ ë‚´ìš©ê³¼ í•¨ê»˜ íˆ¬ì ê´€ì ì—ì„œì˜ í•´ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""
    )
    
    def _run(self, ticker: str, market: str) -> str:
        """
        Run news analysis for the given ticker.
        
        Args:
            ticker: Stock ticker symbol
            market: Market identifier (í•œêµ­ì¥/ë¯¸êµ­ì¥)
            
        Returns:
            News analysis report
        """
        try:
            logger.info(f"Starting news analysis for {ticker} in {market}")
            
            # Mock company name (in real implementation, fetch from stock info)
            company_name = self._get_company_name(ticker, market)
            
            # Collect news data
            news_data = self._collect_news_data(ticker, company_name, market)
            
            # Prepare context for analysis
            context = {
                "ticker": ticker,
                "market": market,
                "company_name": company_name,
                "news_data": self._format_news_data(news_data)
            }
            
            # Generate analysis using LLM
            analysis = self.llm.predict(self.prompt.format(**context))
            
            # Add metadata
            analysis += f"\n\n---\nğŸ“° ë¶„ì„ ì‹œì : {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            analysis += f"\nğŸ“Š ë‰´ìŠ¤ ê°ì„± ì ìˆ˜: {news_data.get('sentiment_score', 'N/A')}"
            analysis += f"\nğŸ¯ ì‹ ë¢°ë„: {self._calculate_confidence(news_data)}"
            
            return analysis
            
        except Exception as e:
            logger.error(f"Error in news analysis: {str(e)}")
            raise AnalysisError(f"ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    def _get_company_name(self, ticker: str, market: str) -> str:
        """Get company name for the ticker."""
        # In real implementation, this would fetch from stock data
        # For now, using a simple mapping
        company_names = {
            "AAPL": "Apple Inc.",
            "MSFT": "Microsoft Corporation",
            "GOOGL": "Alphabet Inc.",
            "AMZN": "Amazon.com Inc.",
            "TSLA": "Tesla Inc.",
            "NVDA": "NVIDIA Corporation",
            "005930": "ì‚¼ì„±ì „ì",
            "000660": "SKí•˜ì´ë‹‰ìŠ¤",
            "035720": "ì¹´ì¹´ì˜¤",
            "035420": "NAVER"
        }
        
        return company_names.get(ticker, ticker)
    
    def _collect_news_data(self, ticker: str, company_name: str, market: str) -> Dict[str, Any]:
        """Collect news and media data."""
        news_data = {}
        
        try:
            # Mock news data collection
            # In real implementation, this would:
            # 1. Fetch from news APIs (Bloomberg, Reuters, etc.)
            # 2. Scrape financial news websites
            # 3. Get social media mentions
            # 4. Analyze Reddit/Twitter sentiment
            
            # Recent news articles (mock data)
            news_data['recent_articles'] = self._get_mock_news_articles(ticker, company_name)
            
            # Sentiment analysis
            news_data['sentiment_analysis'] = self._analyze_news_sentiment(
                news_data['recent_articles']
            )
            
            # Social media metrics
            news_data['social_metrics'] = self._get_mock_social_metrics(ticker)
            
            # Upcoming events
            news_data['upcoming_events'] = self._get_mock_upcoming_events(ticker, company_name)
            
            # News volume trend
            news_data['news_volume'] = self._analyze_news_volume_trend()
            
            # Calculate overall sentiment score
            news_data['sentiment_score'] = self._calculate_overall_sentiment(news_data)
            
        except Exception as e:
            logger.warning(f"Error collecting news data: {e}")
            news_data['error'] = str(e)
        
        return news_data
    
    def _get_mock_news_articles(self, ticker: str, company_name: str) -> List[Dict[str, Any]]:
        """Get mock news articles for demonstration."""
        # In production, this would fetch real news
        base_date = datetime.now()
        
        articles = [
            {
                "title": f"{company_name} 4ë¶„ê¸° ì‹¤ì  ì˜ˆìƒì¹˜ ìƒíšŒ ì „ë§",
                "source": "Financial Times",
                "date": (base_date - timedelta(days=1)).strftime("%Y-%m-%d"),
                "summary": "ì• ë„ë¦¬ìŠ¤íŠ¸ë“¤ì€ ê°•í•œ ìˆ˜ìš”ì™€ ë¹„ìš© ì ˆê°ìœ¼ë¡œ ì‹¤ì  ê°œì„  ì˜ˆìƒ",
                "sentiment": "positive",
                "relevance": 0.95
            },
            {
                "title": f"{company_name} ì‹ ì œí’ˆ ì¶œì‹œ ì„ë°•, ì‹œì¥ ê¸°ëŒ€ê° ìƒìŠ¹",
                "source": "Reuters",
                "date": (base_date - timedelta(days=2)).strftime("%Y-%m-%d"),
                "summary": "í˜ì‹ ì ì¸ ê¸°ëŠ¥ìœ¼ë¡œ ì‹œì¥ ì ìœ ìœ¨ í™•ëŒ€ ê¸°ëŒ€",
                "sentiment": "positive",
                "relevance": 0.88
            },
            {
                "title": f"ê·œì œ ë‹¹êµ­, {company_name} ê´€ë ¨ ì¡°ì‚¬ ì°©ìˆ˜",
                "source": "Bloomberg",
                "date": (base_date - timedelta(days=3)).strftime("%Y-%m-%d"),
                "summary": "ë…ì  ê´€ë ¨ ìš°ë ¤ë¡œ ë‹¹êµ­ ì¡°ì‚¬, ë‹¨ê¸° ë¶ˆí™•ì‹¤ì„± ì¦ê°€",
                "sentiment": "negative",
                "relevance": 0.82
            },
            {
                "title": f"{company_name} CEO, ì¥ê¸° ì„±ì¥ ì „ëµ ë°œí‘œ",
                "source": "CNBC",
                "date": (base_date - timedelta(days=5)).strftime("%Y-%m-%d"),
                "summary": "AI ë° í´ë¼ìš°ë“œ íˆ¬ì í™•ëŒ€, 5ë…„ ë‚´ ë§¤ì¶œ 2ë°° ëª©í‘œ",
                "sentiment": "positive",
                "relevance": 0.90
            }
        ]
        
        return articles
    
    def _analyze_news_sentiment(self, articles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze sentiment from news articles."""
        sentiment_counts = {"positive": 0, "negative": 0, "neutral": 0}
        
        for article in articles:
            sentiment = article.get("sentiment", "neutral")
            sentiment_counts[sentiment] += 1
        
        total = len(articles)
        
        return {
            "positive_ratio": sentiment_counts["positive"] / total if total > 0 else 0,
            "negative_ratio": sentiment_counts["negative"] / total if total > 0 else 0,
            "neutral_ratio": sentiment_counts["neutral"] / total if total > 0 else 0,
            "dominant_sentiment": max(sentiment_counts, key=sentiment_counts.get),
            "total_articles": total
        }
    
    def _get_mock_social_metrics(self, ticker: str) -> Dict[str, Any]:
        """Get mock social media metrics."""
        import random
        
        # Generate some realistic-looking metrics
        base_mentions = random.randint(1000, 10000)
        
        return {
            "twitter_mentions_24h": base_mentions,
            "twitter_sentiment": random.choice(["positive", "neutral", "mixed"]),
            "reddit_mentions_24h": int(base_mentions * 0.3),
            "reddit_top_posts": [
                f"DD: Why ${ticker} is undervalued",
                f"${ticker} technical analysis - breakout incoming?",
                f"Thoughts on ${ticker} earnings?"
            ],
            "stocktwits_sentiment": {
                "bullish": random.randint(55, 75),
                "bearish": random.randint(25, 45)
            },
            "google_trends_score": random.randint(40, 80),
            "mention_growth_7d": f"{random.randint(-20, 50)}%"
        }
    
    def _get_mock_upcoming_events(self, ticker: str, company_name: str) -> List[Dict[str, str]]:
        """Get mock upcoming events."""
        base_date = datetime.now()
        
        events = [
            {
                "date": (base_date + timedelta(days=7)).strftime("%Y-%m-%d"),
                "event": "Q4 ì‹¤ì  ë°œí‘œ",
                "importance": "high",
                "expected_impact": "ì£¼ê°€ ë³€ë™ì„± ì¦ê°€ ì˜ˆìƒ"
            },
            {
                "date": (base_date + timedelta(days=14)).strftime("%Y-%m-%d"),
                "event": "ì‹ ì œí’ˆ ë°œí‘œ ì´ë²¤íŠ¸",
                "importance": "medium",
                "expected_impact": "ê¸ì •ì  ë°˜ì‘ ì˜ˆìƒ"
            },
            {
                "date": (base_date + timedelta(days=30)).strftime("%Y-%m-%d"),
                "event": "ì—°ë¡€ ì£¼ì£¼ì´íšŒ",
                "importance": "medium",
                "expected_impact": "ê²½ì˜ ì „ëµ ë°œí‘œ ì£¼ëª©"
            }
        ]
        
        return events
    
    def _analyze_news_volume_trend(self) -> Dict[str, Any]:
        """Analyze news volume trend."""
        import random
        
        # Mock news volume data
        current_volume = random.randint(50, 200)
        avg_volume = random.randint(40, 100)
        
        return {
            "current_24h": current_volume,
            "average_24h": avg_volume,
            "volume_ratio": current_volume / avg_volume,
            "trend": "increasing" if current_volume > avg_volume * 1.2 else 
                    "decreasing" if current_volume < avg_volume * 0.8 else "stable",
            "unusual_activity": current_volume > avg_volume * 1.5
        }
    
    def _calculate_overall_sentiment(self, news_data: Dict[str, Any]) -> float:
        """Calculate overall sentiment score (0-100)."""
        score = 50  # Neutral baseline
        
        # News sentiment component
        sentiment = news_data.get('sentiment_analysis', {})
        score += (sentiment.get('positive_ratio', 0) - sentiment.get('negative_ratio', 0)) * 30
        
        # Social media component
        social = news_data.get('social_metrics', {})
        if social.get('twitter_sentiment') == 'positive':
            score += 10
        elif social.get('twitter_sentiment') == 'negative':
            score -= 10
            
        # StockTwits sentiment
        stocktwits = social.get('stocktwits_sentiment', {})
        bullish_pct = stocktwits.get('bullish', 50)
        score += (bullish_pct - 50) * 0.4
        
        # News volume (high volume can be good or bad, so smaller weight)
        volume = news_data.get('news_volume', {})
        if volume.get('unusual_activity'):
            # Combine with sentiment direction
            if sentiment.get('dominant_sentiment') == 'positive':
                score += 5
            elif sentiment.get('dominant_sentiment') == 'negative':
                score -= 5
        
        # Ensure score is within bounds
        return max(0, min(100, score))
    
    def _format_news_data(self, data: Dict[str, Any]) -> str:
        """Format news data for prompt."""
        formatted = []
        
        # Overall sentiment score
        sentiment_score = data.get('sentiment_score', 50)
        sentiment_desc = "ë§¤ìš° ë¶€ì •ì " if sentiment_score < 20 else \
                        "ë¶€ì •ì " if sentiment_score < 40 else \
                        "ì¤‘ë¦½" if sentiment_score < 60 else \
                        "ê¸ì •ì " if sentiment_score < 80 else "ë§¤ìš° ê¸ì •ì "
        
        formatted.append(f"ì „ì²´ ë‰´ìŠ¤ ê°ì„±: {sentiment_score:.0f}/100 ({sentiment_desc})")
        formatted.append("")
        
        # Recent articles
        if 'recent_articles' in data:
            formatted.append("ìµœê·¼ ì£¼ìš” ë‰´ìŠ¤:")
            for article in data['recent_articles'][:5]:  # Top 5 articles
                formatted.append(f"\n[{article['date']}] {article['title']}")
                formatted.append(f"  ì¶œì²˜: {article['source']}")
                formatted.append(f"  ìš”ì•½: {article['summary']}")
                formatted.append(f"  ê°ì„±: {article['sentiment']} (ê´€ë ¨ë„: {article['relevance']:.0%})")
            formatted.append("")
        
        # Sentiment analysis
        if 'sentiment_analysis' in data:
            sent = data['sentiment_analysis']
            formatted.append("ë‰´ìŠ¤ ê°ì„± ë¶„ì„:")
            formatted.append(f"- ê¸ì •: {sent.get('positive_ratio', 0):.0%}")
            formatted.append(f"- ë¶€ì •: {sent.get('negative_ratio', 0):.0%}")
            formatted.append(f"- ì¤‘ë¦½: {sent.get('neutral_ratio', 0):.0%}")
            formatted.append(f"- ì£¼ìš” ê°ì„±: {sent.get('dominant_sentiment', 'N/A')}")
            formatted.append("")
        
        # Social media metrics
        if 'social_metrics' in data:
            social = data['social_metrics']
            formatted.append("ì†Œì…œ ë¯¸ë””ì–´ ì§€í‘œ:")
            formatted.append(f"- Twitter ì–¸ê¸‰ (24h): {social.get('twitter_mentions_24h', 0):,}")
            formatted.append(f"- Reddit ì–¸ê¸‰ (24h): {social.get('reddit_mentions_24h', 0):,}")
            formatted.append(f"- StockTwits: ê°•ì„¸ {social.get('stocktwits_sentiment', {}).get('bullish', 0)}% / ì•½ì„¸ {social.get('stocktwits_sentiment', {}).get('bearish', 0)}%")
            formatted.append(f"- ì–¸ê¸‰ ì¦ê°€ìœ¨ (7ì¼): {social.get('mention_growth_7d', 'N/A')}")
            formatted.append("")
        
        # Upcoming events
        if 'upcoming_events' in data:
            formatted.append("ì˜ˆì •ëœ ì£¼ìš” ì´ë²¤íŠ¸:")
            for event in data['upcoming_events']:
                formatted.append(f"- {event['date']}: {event['event']} (ì¤‘ìš”ë„: {event['importance']})")
                formatted.append(f"  ì˜ˆìƒ ì˜í–¥: {event['expected_impact']}")
            formatted.append("")
        
        # News volume
        if 'news_volume' in data:
            volume = data['news_volume']
            formatted.append("ë‰´ìŠ¤ ë³¼ë¥¨ ë¶„ì„:")
            formatted.append(f"- í˜„ì¬ (24h): {volume.get('current_24h', 0)}ê±´")
            formatted.append(f"- í‰ê·  ëŒ€ë¹„: {volume.get('volume_ratio', 1):.1f}x")
            formatted.append(f"- ì¶”ì„¸: {volume.get('trend', 'N/A')}")
            if volume.get('unusual_activity'):
                formatted.append("- âš ï¸ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ë‰´ìŠ¤ í™œë™ ê°ì§€")
        
        return "\n".join(formatted)
    
    def _calculate_confidence(self, data: Dict[str, Any]) -> str:
        """Calculate confidence level based on data quality and volume."""
        if 'error' in data:
            return "ë‚®ìŒ"
        
        # Check data completeness and quality
        confidence_factors = [
            len(data.get('recent_articles', [])) >= 3,
            'sentiment_analysis' in data,
            'social_metrics' in data,
            data.get('sentiment_analysis', {}).get('total_articles', 0) >= 5,
            data.get('news_volume', {}).get('current_24h', 0) >= 20
        ]
        
        confidence_score = sum(confidence_factors) / len(confidence_factors)
        
        if confidence_score >= 0.8:
            return "ë†’ìŒ"
        elif confidence_score >= 0.5:
            return "ë³´í†µ"
        else:
            return "ë‚®ìŒ"