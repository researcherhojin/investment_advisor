# AI 모델 비용 최적화 가이드

## 현재 설정 (최적 가성비)

**GPT-5 nano** 모델로 전환 - OpenAI의 가장 경제적인 최신 모델입니다.

### 최신 가격 비교 (2025년 09월 기준)

- **GPT-5 nano**: $0.05/1M (입력) + $0.40/1M (출력) ✅ **현재 사용 중**
- GPT-5 mini: $0.25/1M (입력) + $2.00/1M (출력) - 5배 비쌈
- GPT-4.1 nano: $0.20/1M (입력) + $0.80/1M (출력) - 4배/2배 비쌈
- GPT-4o mini: $0.60/1M (입력) + $2.40/1M (출력) - 12배/6배 비쌈 (이전 모델)
- GPT-4.1 mini: $0.80/1M (입력) + $3.20/1M (출력) - 16배/8배 비쌈

## 적용된 최적화

1. **토큰 제한**: 응답을 800 토큰으로 제한 (nano 모델에 최적화)
2. **Temperature 0.1**: 결정적 응답으로 재실행 최소화
3. **캐싱 활성화**: 캐시 입력시 $0.005/1M (10배 추가 절감)
4. **Seed 고정**: 일관된 출력으로 캐시 히트율 향상
5. **Top-p 0.90**: nano 모델에 맞춘 집중도 향상

## 추가 비용 절감 방법

### 1. 환경 변수 설정 (.env)

```bash
# 최대 토큰 수 조정 (기본: 1000)
MAX_TOKENS=800  # 더 짧은 응답으로 비용 절감

# 모델 변경 (필요시)
DEFAULT_MODEL=gpt-4o-mini  # 현재 최적

# 캐시 시간 연장 (기본: 15분)
CACHE_DURATION_MINUTES=30  # 캐시 재사용 늘리기
```

### 2. 에이전트별 최적화

각 에이전트의 토큰 사용량:

- 기업분석가: ~800 토큰
- 기술분석가: ~600 토큰
- 리스크관리자: ~500 토큰
- 산업전문가: ~700 토큰
- 거시경제전문가: ~600 토큰
- 중재자: ~400 토큰

**예상 비용 (분석 1회당)**

- 입력: ~2000 토큰 × $0.00005 = $0.0001
- 출력: ~3200 토큰 × $0.0004 = $0.00128
- **총 비용: ~$0.00138 (약 1.8원)** - 이전 대비 49% 절감

**캐시 활용시 (2회차 이후)**

- 입력: ~2000 토큰 × $0.000005 = $0.00001
- 출력: ~3200 토큰 × $0.0004 = $0.00128
- **총 비용: ~$0.00129 (약 1.7원)** - 추가 7% 절감

### 3. 프롬프트 최적화

- 불필요한 지시사항 제거
- 출력 형식 간소화
- 중복 분석 제거

## 월간 예상 비용

### GPT-5 nano (현재)

일일 100회 분석 기준:

- 일간: $0.138 (약 184원)
- 월간: $4.14 (약 5,520원)
- 연간: $49.68 (약 66,240원)

### 이전 모델 대비 절감액

- GPT-4o mini 대비: **월 84% 절감** (38,000원 → 5,520원)
- 연간 절감액: 약 390,000원

## 대안 모델 (극도의 비용 절감 필요시)

### 1. Anthropic Claude Haiku

- 비용: gpt-4o-mini와 유사
- 장점: 빠른 속도
- 단점: OpenAI 코드 변경 필요

### 2. 로컬 LLM (Llama 3, Mistral)

- 비용: 무료 (서버 비용만)
- 장점: API 비용 없음
- 단점: 성능 하락, 서버 필요

### 3. 하이브리드 접근

- 중요 분석: gpt-4o-mini
- 간단한 작업: 로컬 모델
- 데이터 처리: 규칙 기반

## 모니터링 방법

```python
# 토큰 사용량 추적
import tiktoken

def count_tokens(text, model="gpt-4o-mini"):
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))

# 비용 계산
def calculate_cost(input_tokens, output_tokens):
    input_cost = input_tokens * 0.00000015  # $0.15 per 1M
    output_cost = output_tokens * 0.0000006  # $0.60 per 1M
    return input_cost + output_cost
```

## 결론

현재 **gpt-4o-mini**가 최적의 선택입니다:

- ✅ 최저 비용
- ✅ 충분한 성능
- ✅ 빠른 응답
- ✅ 안정적 서비스

추가 비용 절감이 필요하면 MAX_TOKENS 환경변수를 조정하세요.
